services:
  litellm:
    image: ghcr.io/berriai/litellm:${LITELLM_VERSION}
    container_name: litellm
    ports:
      - "${LITELLM_PORT}:4000"
    restart: unless-stopped

  openwebui:
    image: ghcr.io/open-webui/open-webui:${OPENWEBUI_VERSION}
    container_name: openwebui
    environment:
      - OPENAI_API_BASE_URL=http://litellm:4000
      - OPENAI_API_KEY=${LITELLM_API_KEY}
    ports:
      - "${OPENWEBUI_PORT}:8080"
    depends_on:
      - litellm
    restart: unless-stopped
